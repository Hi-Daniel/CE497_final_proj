{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Deep Cognitive Features from Bridge Inspectors Eye Tracking Data\n",
    "\n",
    "Previous to this study we collected data from five different PhD engineering students on the task of inspecting a bridge in a virtual environment. The students were given 3 minutes to inspect a bridge inside of a Unity platform that we have developed, and take images of any defects, cracks, or areas of concern that they found on the bridge. During their inspection we collected data of their character's movement as well as eye movement. Below you see an example of the type of data that was obtained at one time step:\n",
    "\n",
    "```xml\n",
    "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
    "<Data>\n",
    "  <GazeData>\n",
    "    <DisplayDimensions Width=\"1920\" Height=\"1080\" />\n",
    "    <Timestamp>902049965729</Timestamp>\n",
    "    <GazeOrigin>\n",
    "      <CombinedGazeRayScreen Origin=\"(7656.03600000, 927.89240000, -1049.60500000)\" Direction=\"(-0.95211820, -0.28659020, 0.10647600)\" Valid=\"True\" />\n",
    "    </GazeOrigin>\n",
    "    <pupil average_pupildiameter=\"4.157799\" />\n",
    "    <IntersectionPoint X=\"4420.004\" Y=\"-46.16226\" Z=\"-687.7166\" />\n",
    "    <HitObject Name=\"RW_Bridge_Vologda_II_track_LOD0\">\n",
    "      <ObjectPosition X=\"0\" Y=\"0\" Z=\"0\" />\n",
    "    </HitObject>\n",
    "    <PositionOnDisplayArea X=\"0.5182106\" Y=\"0.5221348\" />\n",
    "  </GazeData>\n",
    "  <CameraData>\n",
    "    <Timestamp>902049965729</Timestamp>\n",
    "    <CameraOrigin X=\"7656.323\" Y=\"927.9785\" Z=\"-1049.637\" />\n",
    "    <CameraDirection X=\"-0.9624248\" Y=\"-0.2623872\" Z=\"0.06994079\" />\n",
    "  </CameraData>\n",
    "<Data>\n",
    "```\n",
    "\n",
    "One can see information such as the time of the data point, the location and viewing direction of the inspector at this time as well as the location where their eye were looking. This data was collected at a rate of 60 fps, therefore for 3 minutes of data we have 5400 data points.\n",
    "\n",
    "### Goal\n",
    "\n",
    "Our goal in this experiment is to determine whether we can use machine learning to make insights into the cognitive behavior of the inspectors based on this eye tracking data. For example, a successful insight would be if we can correctly identify whether a person is planning, searching, or deciding at every point in their search. For example, when the person is first planning where on the bridge to look, then the person might be actively looking, once the person finds something interesting such as a crack they will be deciding whether this is something they should take a picture of or not.\n",
    "\n",
    "In addition to these fine-scaled, granular behavioral patterns, we would also like to see if machine learning methods can identify more \"big picture\" patterns, such as classifying search styles based on a larger set of data.\n",
    "\n",
    "We believe that the insights gathered from these methods can be used as tools to make concrete data-driven decisions for designing training procedures for new inspectors, or comparing the efficiency of different inspection patterns.\n",
    "\n",
    "### Methodology\n",
    "\n",
    "In order to extract deep features from our data we propose two methods. \n",
    "\n",
    "The first method consists of using dimensionality reduction and clustering techniques such as PCA, t-SNE, and k-means on manually extracted feature vectors, such as velocity, acceleration, rate of fixations to saccades, etc. Then investigating these reduced dimensionality arrays to determine which combination of features creates the most meaningful feature space.\n",
    "\n",
    "The second method involves using similar dimensionality reduction techniques on feature vectors extracted from unsupervised feature extraction techniques such as Deep Autoencoders, Variational Autoencoders, LSTM Autoencoders, etc.\n",
    "\n",
    "We will then visualize the two methods and extract clusters of points, then we will interpret the clusters to find whether they correspond to certain parts of the inspection process or different search patterns. We can apply both of these methods on a global as well as local level to get different types of clustering.\n",
    "\n",
    "For example, if we apply the method \"locally\" meaning that we divide the dataset into 1 second intervals and perform the clustering on these 1 second intervals then we expect the clusters to represent local/short term cognitive behavior such as whether a person is searching or planning.\n",
    "\n",
    "On the other hand, if we perform the clustering \"globally\" meaning that we use the entire data record we expect the clusters to represent more global characteristics about the search, such as search strategy, or who the inspector is.\n",
    "\n",
    "Something to keep in mind is that we want to anonymize the data records as much as possible to avoid clustering based on trivial factors such as the exact locations that inspectors looked at or other features that wouldn't generalize well and wouldn't truly represent an inspector's cognitive behavior.\n",
    "\n",
    "### Table of Contents (TO-DO)\n",
    "\n",
    "\n",
    "<ul>\n",
    "    <li>Loading Data</li>\n",
    "    <li>Local clustering</li>\n",
    "        <ul>\n",
    "            <li>Breaking up the data</li>\n",
    "            <li>Method 1\n",
    "                <ul>\n",
    "                    <li>Extracting manual features</li>\n",
    "                    <li>Trying different clustering techniques</li>\n",
    "                    <li>Visualizing clusters</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>Method 2\n",
    "                <ul>\n",
    "                    <li>Training Deep AE, VAE, and LSTM AE</li>\n",
    "                    <li>Extracting deep features</li>\n",
    "                    <li>Clustering / dimensionality reduction of deep features</li>\n",
    "                    <li>Visualizing clusters</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>Testing generality of clusters</li>\n",
    "            <li>Findings and conclusions</li>\n",
    "        </ul>\n",
    "    <li>Global clustering\n",
    "        <ul>\n",
    "            <li>Extracting manual global features</li>\n",
    "            <li>Extracting deep features (Training extractor model)</li>\n",
    "            <li>Clustering techniques</li>\n",
    "            <li>Visualizing clusters</li>\n",
    "            <li>Testing generality of clusters</li>\n",
    "            <li>Findings and conclusions</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data <a name=\"loading-data\"></a>\n",
    "\n",
    "In this section we will load the data from the different users' xml files.\n",
    "\n",
    "The data is located in the test_1 folder. The files are divided into two data records for each user, the first data record is for the task of bridge inspection (with suffix \"_truss.xml\"). The second data record is for the task of looking for a certain object inside a warehouse (with suffix \"_warehouse.xml\"). We will use the second data record for testing the generality of our clusters, but not for generating the classifiers themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_loader' from 'c:\\\\Users\\\\xavie\\\\Documents\\\\2025\\\\02 UIUC SPRING 2025\\\\02 CEE498 ML\\\\03 Project\\\\02 GitHub Docs\\\\eyeDataViz\\\\CE497_final_proj\\\\data_loader.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm # Use notebook version for better display\n",
    "import importlib\n",
    "import data_loader\n",
    "importlib.reload(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 XML files in test_1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe1000b1cad4d10ba0741c23dc5e699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading XML files:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Ishfaq_truss.xml (17 rows) as key 'Ishfaq_truss'\n",
      "Loaded Ishfaq_warehouse.xml (17 rows) as key 'Ishfaq_warehouse'\n",
      "Loaded Mohamad_truss.xml (17 rows) as key 'Mohamad_truss'\n",
      "Loaded Mohamad_warehouse.xml (17 rows) as key 'Mohamad_warehouse'\n",
      "Loaded Runze_truss.xml (17 rows) as key 'Runze_truss'\n",
      "Loaded Runze_warehouse.xml (17 rows) as key 'Runze_warehouse'\n",
      "Loaded Yuxiang_truss.xml (17 rows) as key 'Yuxiang_truss'\n",
      "Loaded Yuxiang_warehouse.xml (17 rows) as key 'Yuxiang_warehouse'\n",
      "\n",
      "Loaded 4 truss datasets.\n",
      "Loaded 4 warehouse datasets.\n",
      "\n",
      "Head of data for 'Ishfaq_truss':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_sec</th>\n",
       "      <th>X_2d_X</th>\n",
       "      <th>X_2d_Y</th>\n",
       "      <th>PupilDiameter</th>\n",
       "      <th>GazeOrigin_X</th>\n",
       "      <th>GazeOrigin_Y</th>\n",
       "      <th>GazeOrigin_Z</th>\n",
       "      <th>GazeDirection_X</th>\n",
       "      <th>GazeDirection_Y</th>\n",
       "      <th>GazeDirection_Z</th>\n",
       "      <th>CameraDirection_X</th>\n",
       "      <th>CameraDirection_Y</th>\n",
       "      <th>CameraDirection_Z</th>\n",
       "      <th>CameraOrigin_X</th>\n",
       "      <th>CameraOrigin_Y</th>\n",
       "      <th>CameraOrigin_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.518211</td>\n",
       "      <td>0.522135</td>\n",
       "      <td>4.157799</td>\n",
       "      <td>7656.036</td>\n",
       "      <td>927.8924</td>\n",
       "      <td>-1049.605</td>\n",
       "      <td>-0.952118</td>\n",
       "      <td>-0.286590</td>\n",
       "      <td>0.106476</td>\n",
       "      <td>-0.962425</td>\n",
       "      <td>-0.262387</td>\n",
       "      <td>0.069941</td>\n",
       "      <td>7656.323</td>\n",
       "      <td>927.9785</td>\n",
       "      <td>-1049.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017018</td>\n",
       "      <td>0.515912</td>\n",
       "      <td>0.527296</td>\n",
       "      <td>4.175835</td>\n",
       "      <td>7656.037</td>\n",
       "      <td>927.8907</td>\n",
       "      <td>-1049.606</td>\n",
       "      <td>-0.950918</td>\n",
       "      <td>-0.292255</td>\n",
       "      <td>0.101698</td>\n",
       "      <td>-0.962425</td>\n",
       "      <td>-0.262387</td>\n",
       "      <td>0.069941</td>\n",
       "      <td>7656.323</td>\n",
       "      <td>927.9785</td>\n",
       "      <td>-1049.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.033244</td>\n",
       "      <td>0.491616</td>\n",
       "      <td>0.474780</td>\n",
       "      <td>4.185173</td>\n",
       "      <td>7656.031</td>\n",
       "      <td>927.9082</td>\n",
       "      <td>-1049.621</td>\n",
       "      <td>-0.970788</td>\n",
       "      <td>-0.233966</td>\n",
       "      <td>0.053210</td>\n",
       "      <td>-0.962425</td>\n",
       "      <td>-0.262387</td>\n",
       "      <td>0.069941</td>\n",
       "      <td>7656.323</td>\n",
       "      <td>927.9785</td>\n",
       "      <td>-1049.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.049965</td>\n",
       "      <td>0.488096</td>\n",
       "      <td>0.398515</td>\n",
       "      <td>4.163857</td>\n",
       "      <td>7656.024</td>\n",
       "      <td>927.9337</td>\n",
       "      <td>-1049.622</td>\n",
       "      <td>-0.987827</td>\n",
       "      <td>-0.148152</td>\n",
       "      <td>0.047419</td>\n",
       "      <td>-0.962425</td>\n",
       "      <td>-0.262387</td>\n",
       "      <td>0.069941</td>\n",
       "      <td>7656.323</td>\n",
       "      <td>927.9785</td>\n",
       "      <td>-1049.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.066835</td>\n",
       "      <td>0.499238</td>\n",
       "      <td>0.321722</td>\n",
       "      <td>4.161942</td>\n",
       "      <td>7656.018</td>\n",
       "      <td>927.9594</td>\n",
       "      <td>-1049.615</td>\n",
       "      <td>-0.995547</td>\n",
       "      <td>-0.062378</td>\n",
       "      <td>0.070678</td>\n",
       "      <td>-0.962425</td>\n",
       "      <td>-0.262387</td>\n",
       "      <td>0.069941</td>\n",
       "      <td>7656.323</td>\n",
       "      <td>927.9785</td>\n",
       "      <td>-1049.637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time_sec    X_2d_X    X_2d_Y  PupilDiameter  GazeOrigin_X  GazeOrigin_Y  \\\n",
       "0  0.000000  0.518211  0.522135       4.157799      7656.036      927.8924   \n",
       "1  0.017018  0.515912  0.527296       4.175835      7656.037      927.8907   \n",
       "2  0.033244  0.491616  0.474780       4.185173      7656.031      927.9082   \n",
       "3  0.049965  0.488096  0.398515       4.163857      7656.024      927.9337   \n",
       "4  0.066835  0.499238  0.321722       4.161942      7656.018      927.9594   \n",
       "\n",
       "   GazeOrigin_Z  GazeDirection_X  GazeDirection_Y  GazeDirection_Z  \\\n",
       "0     -1049.605        -0.952118        -0.286590         0.106476   \n",
       "1     -1049.606        -0.950918        -0.292255         0.101698   \n",
       "2     -1049.621        -0.970788        -0.233966         0.053210   \n",
       "3     -1049.622        -0.987827        -0.148152         0.047419   \n",
       "4     -1049.615        -0.995547        -0.062378         0.070678   \n",
       "\n",
       "   CameraDirection_X  CameraDirection_Y  CameraDirection_Z  CameraOrigin_X  \\\n",
       "0          -0.962425          -0.262387           0.069941        7656.323   \n",
       "1          -0.962425          -0.262387           0.069941        7656.323   \n",
       "2          -0.962425          -0.262387           0.069941        7656.323   \n",
       "3          -0.962425          -0.262387           0.069941        7656.323   \n",
       "4          -0.962425          -0.262387           0.069941        7656.323   \n",
       "\n",
       "   CameraOrigin_Y  CameraOrigin_Z  \n",
       "0        927.9785       -1049.637  \n",
       "1        927.9785       -1049.637  \n",
       "2        927.9785       -1049.637  \n",
       "3        927.9785       -1049.637  \n",
       "4        927.9785       -1049.637  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Info for 'Ishfaq_truss':\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11524 entries, 0 to 11523\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Time_sec           11524 non-null  float64\n",
      " 1   X_2d_X             11029 non-null  float64\n",
      " 2   X_2d_Y             11029 non-null  float64\n",
      " 3   PupilDiameter      11029 non-null  float64\n",
      " 4   GazeOrigin_X       11524 non-null  float64\n",
      " 5   GazeOrigin_Y       11524 non-null  float64\n",
      " 6   GazeOrigin_Z       11524 non-null  float64\n",
      " 7   GazeDirection_X    11524 non-null  float64\n",
      " 8   GazeDirection_Y    11524 non-null  float64\n",
      " 9   GazeDirection_Z    11524 non-null  float64\n",
      " 10  CameraDirection_X  11524 non-null  float64\n",
      " 11  CameraDirection_Y  11524 non-null  float64\n",
      " 12  CameraDirection_Z  11524 non-null  float64\n",
      " 13  CameraOrigin_X     11524 non-null  float64\n",
      " 14  CameraOrigin_Y     11524 non-null  float64\n",
      " 15  CameraOrigin_Z     11524 non-null  float64\n",
      "dtypes: float64(16)\n",
      "memory usage: 1.5 MB\n",
      "\n",
      "Truss Data Keys: ['Ishfaq_truss', 'Mohamad_truss', 'Runze_truss', 'Yuxiang_truss']\n",
      "\n",
      "Warehouse Data Keys: ['Ishfaq_warehouse', 'Mohamad_warehouse', 'Runze_warehouse', 'Yuxiang_warehouse']\n"
     ]
    }
   ],
   "source": [
    "# Set plot style\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\", color_codes=True)\n",
    "\n",
    "# Specify the folder containing the XML data\n",
    "DATA_FOLDER = \"test_1\" # Make sure this folder exists relative to the notebook\n",
    "# Load the data\n",
    "truss_data, warehouse_data = data_loader.load_all_data(DATA_FOLDER)\n",
    "\n",
    "# Display some basic info about the loaded data\n",
    "if truss_data:\n",
    "    # Example: Display head of the first truss dataset\n",
    "    first_key = list(truss_data.keys())[0]\n",
    "    print(f\"\\nHead of data for '{first_key}':\")\n",
    "    first_key_df = data_loader.data_dict_to_df(truss_data[first_key])\n",
    "    display(first_key_df.head())\n",
    "    print(f\"\\nInfo for '{first_key}':\")\n",
    "    first_key_df.info()\n",
    "\n",
    "print(\"\\nTruss Data Keys:\", list(truss_data.keys()))\n",
    "print(\"\\nWarehouse Data Keys:\", list(warehouse_data.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Clustering\n",
    "### Breaking up the data <a name=\"break-up-data\"></a>\n",
    "\n",
    "For performing local clustering we would like to gather features that represent cognitive behavior at one instance in time. For example, is the person planning right now or are they actively searching? To achieve this we propose to first break up our data records into small instances of time (such as 1s) and then perform the clustering and subsequent analysis on these short time records.\n",
    "\n",
    "Equally as important, we must anonymize these short time records in order to avoid clustering based on trivial facts. For example, if not anonymized, the clustering analysis could yield clusters that simply divide the data based on location (Such as looking at the top of the deck vs the bottom) but these clusters do not provide any insight into the person's cognitive behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size: 1.0 seconds (60 data points)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef504380a8c2477ebb7d4201c221fc98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating & Anonymizing Windows:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 'Ishfaq_truss': Created 1043 raw windows -> 1043 anonymized windows.\n",
      "Processed 'Mohamad_truss': Created 1014 raw windows -> 1014 anonymized windows.\n",
      "Processed 'Runze_truss': Created 1023 raw windows -> 1023 anonymized windows.\n",
      "Processed 'Yuxiang_truss': Created 1159 raw windows -> 1159 anonymized windows.\n",
      "\n",
      "Head of first anonymized window for 'Ishfaq_truss':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_sec</th>\n",
       "      <th>X_2d_X</th>\n",
       "      <th>X_2d_Y</th>\n",
       "      <th>PupilDiameter</th>\n",
       "      <th>GazeOrigin_X</th>\n",
       "      <th>GazeOrigin_Y</th>\n",
       "      <th>GazeOrigin_Z</th>\n",
       "      <th>GazeDirection_X</th>\n",
       "      <th>GazeDirection_Y</th>\n",
       "      <th>GazeDirection_Z</th>\n",
       "      <th>CameraDirection_X</th>\n",
       "      <th>CameraDirection_Y</th>\n",
       "      <th>CameraDirection_Z</th>\n",
       "      <th>CameraOrigin_X</th>\n",
       "      <th>CameraOrigin_Y</th>\n",
       "      <th>CameraOrigin_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.518211</td>\n",
       "      <td>0.522135</td>\n",
       "      <td>4.157799</td>\n",
       "      <td>5104.027133</td>\n",
       "      <td>618.581083</td>\n",
       "      <td>-699.743533</td>\n",
       "      <td>-0.952118</td>\n",
       "      <td>-0.286590</td>\n",
       "      <td>0.106476</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-5.551115e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.273737e-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017018</td>\n",
       "      <td>0.515912</td>\n",
       "      <td>0.527296</td>\n",
       "      <td>4.175835</td>\n",
       "      <td>5104.028133</td>\n",
       "      <td>618.579383</td>\n",
       "      <td>-699.744533</td>\n",
       "      <td>-0.950918</td>\n",
       "      <td>-0.292255</td>\n",
       "      <td>0.101698</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-5.551115e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.273737e-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.033244</td>\n",
       "      <td>0.491616</td>\n",
       "      <td>0.474780</td>\n",
       "      <td>4.185173</td>\n",
       "      <td>5104.022133</td>\n",
       "      <td>618.596883</td>\n",
       "      <td>-699.759533</td>\n",
       "      <td>-0.970788</td>\n",
       "      <td>-0.233966</td>\n",
       "      <td>0.053210</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-5.551115e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.273737e-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.049965</td>\n",
       "      <td>0.488096</td>\n",
       "      <td>0.398515</td>\n",
       "      <td>4.163857</td>\n",
       "      <td>5104.015133</td>\n",
       "      <td>618.622383</td>\n",
       "      <td>-699.760533</td>\n",
       "      <td>-0.987827</td>\n",
       "      <td>-0.148152</td>\n",
       "      <td>0.047419</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-5.551115e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.273737e-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.066835</td>\n",
       "      <td>0.499238</td>\n",
       "      <td>0.321722</td>\n",
       "      <td>4.161942</td>\n",
       "      <td>5104.009133</td>\n",
       "      <td>618.648083</td>\n",
       "      <td>-699.753533</td>\n",
       "      <td>-0.995547</td>\n",
       "      <td>-0.062378</td>\n",
       "      <td>0.070678</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-5.551115e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.273737e-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time_sec    X_2d_X    X_2d_Y  PupilDiameter  GazeOrigin_X  GazeOrigin_Y  \\\n",
       "0  0.000000  0.518211  0.522135       4.157799   5104.027133    618.581083   \n",
       "1  0.017018  0.515912  0.527296       4.175835   5104.028133    618.579383   \n",
       "2  0.033244  0.491616  0.474780       4.185173   5104.022133    618.596883   \n",
       "3  0.049965  0.488096  0.398515       4.163857   5104.015133    618.622383   \n",
       "4  0.066835  0.499238  0.321722       4.161942   5104.009133    618.648083   \n",
       "\n",
       "   GazeOrigin_Z  GazeDirection_X  GazeDirection_Y  GazeDirection_Z  \\\n",
       "0   -699.743533        -0.952118        -0.286590         0.106476   \n",
       "1   -699.744533        -0.950918        -0.292255         0.101698   \n",
       "2   -699.759533        -0.970788        -0.233966         0.053210   \n",
       "3   -699.760533        -0.987827        -0.148152         0.047419   \n",
       "4   -699.753533        -0.995547        -0.062378         0.070678   \n",
       "\n",
       "   CameraDirection_X  CameraDirection_Y  CameraDirection_Z  CameraOrigin_X  \\\n",
       "0       1.110223e-16      -5.551115e-17                0.0             0.0   \n",
       "1       1.110223e-16      -5.551115e-17                0.0             0.0   \n",
       "2       1.110223e-16      -5.551115e-17                0.0             0.0   \n",
       "3       1.110223e-16      -5.551115e-17                0.0             0.0   \n",
       "4       1.110223e-16      -5.551115e-17                0.0             0.0   \n",
       "\n",
       "   CameraOrigin_Y  CameraOrigin_Z  \n",
       "0    2.273737e-13             0.0  \n",
       "1    2.273737e-13             0.0  \n",
       "2    2.273737e-13             0.0  \n",
       "3    2.273737e-13             0.0  \n",
       "4    2.273737e-13             0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in anonymized window:\n",
      "Index(['Time_sec', 'X_2d_X', 'X_2d_Y', 'PupilDiameter', 'GazeOrigin_X',\n",
      "       'GazeOrigin_Y', 'GazeOrigin_Z', 'GazeDirection_X', 'GazeDirection_Y',\n",
      "       'GazeDirection_Z', 'CameraDirection_X', 'CameraDirection_Y',\n",
      "       'CameraDirection_Z', 'CameraOrigin_X', 'CameraOrigin_Y',\n",
      "       'CameraOrigin_Z'],\n",
      "      dtype='object')\n",
      "\n",
      "Info for anonymized window of 'Ishfaq_truss':\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60 entries, 0 to 59\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Time_sec           60 non-null     float64\n",
      " 1   X_2d_X             20 non-null     float64\n",
      " 2   X_2d_Y             20 non-null     float64\n",
      " 3   PupilDiameter      20 non-null     float64\n",
      " 4   GazeOrigin_X       60 non-null     float64\n",
      " 5   GazeOrigin_Y       60 non-null     float64\n",
      " 6   GazeOrigin_Z       60 non-null     float64\n",
      " 7   GazeDirection_X    60 non-null     float64\n",
      " 8   GazeDirection_Y    60 non-null     float64\n",
      " 9   GazeDirection_Z    60 non-null     float64\n",
      " 10  CameraDirection_X  60 non-null     float64\n",
      " 11  CameraDirection_Y  60 non-null     float64\n",
      " 12  CameraDirection_Z  60 non-null     float64\n",
      " 13  CameraOrigin_X     60 non-null     float64\n",
      " 14  CameraOrigin_Y     60 non-null     float64\n",
      " 15  CameraOrigin_Z     60 non-null     float64\n",
      "dtypes: float64(16)\n",
      "memory usage: 8.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "WINDOW_SECONDS = 1.0 # Duration of each local window\n",
    "SAMPLING_RATE = 60 # Hz (data points per second)\n",
    "WINDOW_POINTS = int(WINDOW_SECONDS * SAMPLING_RATE)\n",
    "WINDOW_OVERLAP = 0.8\n",
    "\n",
    "print(f\"Window size: {WINDOW_SECONDS} seconds ({WINDOW_POINTS} data points)\")\n",
    "\n",
    "\n",
    "# Process all truss data\n",
    "all_windows_anonymized = {}\n",
    "for key, data in tqdm(truss_data.items(), desc=\"Creating & Anonymizing Windows\"):\n",
    "    df = data_loader.data_dict_to_df(data)\n",
    "    windows_raw = data_loader.create_windows(df, WINDOW_POINTS, WINDOW_OVERLAP)\n",
    "    anonymized_windows = [data_loader.anonymize_window(w) for w in windows_raw]\n",
    "    all_windows_anonymized[key] = anonymized_windows\n",
    "    print(f\"Processed '{key}': Created {len(windows_raw)} raw windows -> {len(anonymized_windows)} anonymized windows.\")\n",
    "\n",
    "# Example: Display the first anonymized window for the first user\n",
    "if all_windows_anonymized:\n",
    "    first_key = list(all_windows_anonymized.keys())[0]\n",
    "    if all_windows_anonymized[first_key]:\n",
    "        print(f\"\\nHead of first anonymized window for '{first_key}':\")\n",
    "        display(all_windows_anonymized[first_key][0].head())\n",
    "        print(f\"\\nColumns in anonymized window:\")\n",
    "        print(all_windows_anonymized[first_key][0].columns)\n",
    "        # Inspect structure and details of anonymized window\n",
    "        first_window_df = all_windows_anonymized[first_key][0]\n",
    "        print(f\"\\nInfo for anonymized window of '{first_key}':\")\n",
    "        first_window_df.info()\n",
    "    else:\n",
    "        print(f\"No windows created for '{first_key}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1\n",
    "### Extracting manual features <a name=\"manual-feature-extraction\"></a>\n",
    "\n",
    "After anonymizing the data records we will do some manual feature engineering on our data in order to provide more meaningful features for our clustering algorithms. Based on previous literature we have decided to include the following features:\n",
    "\n",
    "1. Eye metrics\n",
    "   - Average pupil diameter (mm)\n",
    "   - Average eye movement velocity (deg/s)\n",
    "   - Average eye movement acceleration (deg/s/s)\n",
    "   - Ratio of fixation/saccade (s)\n",
    "   - Number of fixations\n",
    "   - Average fixation duration (s)\n",
    "   - Spatial variance of fixations (deg)\n",
    "   - Mean saccade velocity (deg/s)\n",
    "   - Mean saccade amplitude (deg)\n",
    "1. Movement patterns (within 1s window)\n",
    "   - Average movement velocity (m/s)\n",
    "   - Average turning velocity (deg/s)\n",
    "   - Total action, including translation and rotation\n",
    "\n",
    "These features are selected to capture cognitive behavior patterns\n",
    "while being meaningful within a 1-second analysis window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdcd116b59c1466f9492c644be45d423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Manual Features:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'AvgPupilDiameter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'AvgPupilDiameter'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 83\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, anonymized_windows \u001b[38;5;129;01min\u001b[39;00m tqdm(all_windows_anonymized\u001b[38;5;241m.\u001b[39mitems(), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating Manual Features\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, window_df \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(anonymized_windows):\n\u001b[1;32m---> 83\u001b[0m         features \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_manual_features_for_window\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m         all_manual_features\u001b[38;5;241m.\u001b[39mappend(features)\n\u001b[0;32m     85\u001b[0m         window_indices\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_task\u001b[39m\u001b[38;5;124m'\u001b[39m: key, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwindow_index\u001b[39m\u001b[38;5;124m'\u001b[39m: i})\n",
      "Cell \u001b[1;32mIn[4], line 29\u001b[0m, in \u001b[0;36mcalculate_manual_features_for_window\u001b[1;34m(window_df)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     12\u001b[0m          \u001b[38;5;66;03m# Eye metrics\u001b[39;00m\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_pupil_diameter\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mnan, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_eye_velocity_degps\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mnan,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_action\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m     22\u001b[0m     }\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Placeholder calculations - Replace with actual implementations\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# based on the anonymized columns (e.g., GazeTurningRate, CameraSpeed)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# and potentially fixation/saccade detection algorithms.\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 1. Eye metrics\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_pupil_diameter\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mwindow_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAvgPupilDiameter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# --- Requires Fixation/Saccade Detection ---\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Placeholder: Need an algorithm (e.g., I-VT, I-DT) to classify points\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# For now, use placeholders or simple proxies if possible\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Example proxy: Use GazeTurningRate threshold\u001b[39;00m\n\u001b[0;32m     35\u001b[0m saccade_threshold_degps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;66;03m# Example threshold\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'AvgPupilDiameter'"
     ]
    }
   ],
   "source": [
    "def calculate_manual_features_for_window(window_df):\n",
    "    \"\"\"\n",
    "    Calculates the 14 manual features for a single anonymized window (DataFrame).\n",
    "    This function will eventually live in feature_engineering.py\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "\n",
    "    if window_df.empty or len(window_df) < 2:\n",
    "        # Return default values or NaNs if window is too short\n",
    "        # Define default/NaN structure based on expected feature names\n",
    "        return {\n",
    "             # Eye metrics\n",
    "            'avg_pupil_diameter': np.nan, 'avg_eye_velocity_degps': np.nan,\n",
    "            'avg_eye_accel_degps2': np.nan, 'fix_sacc_ratio': np.nan,\n",
    "            'n_fixations': 0, 'avg_fixation_duration': np.nan,\n",
    "            'fixation_spatial_variance': np.nan, 'mean_saccade_velocity': np.nan,\n",
    "            'mean_saccade_amplitude': np.nan, 'gaze_area_covered': np.nan,\n",
    "            'gaze_spatial_density': np.nan,\n",
    "             # Movement patterns\n",
    "            'avg_movement_velocity_mps': np.nan, 'avg_turning_velocity_degps': np.nan,\n",
    "            'total_action': np.nan\n",
    "        }\n",
    "\n",
    "    # Placeholder calculations - Replace with actual implementations\n",
    "    # based on the anonymized columns (e.g., GazeTurningRate, CameraSpeed)\n",
    "    # and potentially fixation/saccade detection algorithms.\n",
    "\n",
    "    # 1. Eye metrics\n",
    "    features['avg_pupil_diameter'] = window_df['AvgPupilDiameter'].mean()\n",
    "\n",
    "    # --- Requires Fixation/Saccade Detection ---\n",
    "    # Placeholder: Need an algorithm (e.g., I-VT, I-DT) to classify points\n",
    "    # For now, use placeholders or simple proxies if possible\n",
    "    # Example proxy: Use GazeTurningRate threshold\n",
    "    saccade_threshold_degps = 100 # Example threshold\n",
    "    window_df['is_saccade'] = window_df['GazeTurningRate'].abs() > saccade_threshold_degps\n",
    "    window_df['is_fixation'] = ~window_df['is_saccade']\n",
    "\n",
    "    # Avg eye movement velocity (using GazeTurningRate as proxy)\n",
    "    features['avg_eye_velocity_degps'] = window_df['GazeTurningRate'].abs().mean()\n",
    "    # Avg eye movement acceleration (numerically differentiate velocity)\n",
    "    eye_accel = window_df['GazeTurningRate'].diff().abs() / window_df['dt']\n",
    "    features['avg_eye_accel_degps2'] = eye_accel.mean()\n",
    "\n",
    "    # Fixation/Saccade ratio (duration based)\n",
    "    total_fixation_time = window_df.loc[window_df['is_fixation'], 'dt'].sum()\n",
    "    total_saccade_time = window_df.loc[window_df['is_saccade'], 'dt'].sum()\n",
    "    features['fix_sacc_ratio'] = total_fixation_time / total_saccade_time if total_saccade_time > 0 else np.inf\n",
    "\n",
    "    # --- Fixation-based features (Placeholder implementation) ---\n",
    "    # Need to group consecutive fixation points into fixation events\n",
    "    # This requires more complex logic (event detection)\n",
    "    features['n_fixations'] = window_df['is_fixation'].sum() # Simplistic: count fixation points\n",
    "    features['avg_fixation_duration'] = total_fixation_time / features['n_fixations'] if features['n_fixations'] > 0 else 0\n",
    "    features['fixation_spatial_variance'] = np.nan # Requires fixation locations\n",
    "    features['mean_saccade_velocity'] = window_df.loc[window_df['is_saccade'], 'GazeTurningRate'].abs().mean() # Proxy\n",
    "    features['mean_saccade_amplitude'] = np.nan # Requires saccade start/end points\n",
    "    features['gaze_area_covered'] = np.nan # Requires gaze points (e.g., IntersectionPoint or PositionOnDisplay)\n",
    "    features['gaze_spatial_density'] = np.nan # Requires gaze points\n",
    "\n",
    "    # 2. Movement patterns\n",
    "    features['avg_movement_velocity_mps'] = window_df['CameraSpeed'].mean()\n",
    "    features['avg_turning_velocity_degps'] = window_df['CameraTurningRate'].abs().mean()\n",
    "    # Total action: Combine translation and rotation (needs weighting/scaling)\n",
    "    # Example: simple sum of mean speeds (needs normalization/better definition)\n",
    "    normalized_speed = features['avg_movement_velocity_mps'] / (window_df['CameraSpeed'].max() + 1e-6)\n",
    "    normalized_turn = features['avg_turning_velocity_degps'] / (window_df['CameraTurningRate'].abs().max() + 1e-6)\n",
    "    features['total_action'] = normalized_speed + normalized_turn # Simplistic combination\n",
    "\n",
    "    # Clean up NaNs/Infs resulting from calculations\n",
    "    for key, value in features.items():\n",
    "        if pd.isna(value) or np.isinf(value):\n",
    "            features[key] = 0 # Replace with 0 or another suitable default\n",
    "\n",
    "    return features\n",
    "\n",
    "# Calculate features for all anonymized windows\n",
    "all_manual_features = []\n",
    "window_indices = [] # Keep track of which user/window each feature row corresponds to\n",
    "\n",
    "for key, anonymized_windows in tqdm(all_windows_anonymized.items(), desc=\"Calculating Manual Features\"):\n",
    "    for i, window_df in enumerate(anonymized_windows):\n",
    "        features = calculate_manual_features_for_window(window_df)\n",
    "        all_manual_features.append(features)\n",
    "        window_indices.append({'user_task': key, 'window_index': i})\n",
    "\n",
    "# Create DataFrames\n",
    "manual_features_df = pd.DataFrame(all_manual_features)\n",
    "window_indices_df = pd.DataFrame(window_indices)\n",
    "\n",
    "# Combine indices with features\n",
    "manual_features_df = pd.concat([window_indices_df, manual_features_df], axis=1)\n",
    "\n",
    "print(\"\\nManual Features DataFrame:\")\n",
    "display(manual_features_df.head())\n",
    "print(\"\\nInfo:\")\n",
    "manual_features_df.info()\n",
    "print(\"\\nDescription:\")\n",
    "display(manual_features_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying different clustering techniques <a name=\"clustering1\"></a>\n",
    "\n",
    "In this section we will apply clustering techniques to the manual features created above. We will apply the following techniques and explore the clusters created.\n",
    "\n",
    "1. PCA\n",
    "2. T-SNE\n",
    "3. K-means\n",
    "4. Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "# --- Data Preparation ---\n",
    "# Select only the numeric feature columns for clustering\n",
    "feature_columns = manual_features_df.select_dtypes(include=np.number).columns\n",
    "# Drop columns that might be constant or have zero variance if they exist\n",
    "# Also drop index/identifier columns if they were included by mistake\n",
    "feature_columns = feature_columns.drop(['window_index'], errors='ignore')\n",
    "\n",
    "print(f\"Using features for clustering: {feature_columns.tolist()}\")\n",
    "\n",
    "# Handle potential NaN/Inf values if not already done during feature extraction\n",
    "features_for_clustering = manual_features_df[feature_columns].fillna(0).replace([np.inf, -np.inf], 0)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features_for_clustering)\n",
    "\n",
    "print(f\"Scaled features shape: {scaled_features.shape}\")\n",
    "\n",
    "# --- 1. PCA (Dimensionality Reduction & Visualization) ---\n",
    "print(\"\\n--- Performing PCA ---\")\n",
    "pca = PCA(n_components=2) # Reduce to 2 dimensions for visualization\n",
    "pca_result = pca.fit_transform(scaled_features)\n",
    "print(f\"Explained variance ratio (first 2 components): {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total explained variance: {pca.explained_variance_ratio_.sum():.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(x=pca_result[:, 0], y=pca_result[:, 1], alpha=0.6)\n",
    "plt.title('PCA of Manual Features (First 2 Components)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- 2. T-SNE (Dimensionality Reduction & Visualization) ---\n",
    "print(\"\\n--- Performing T-SNE ---\")\n",
    "# Note: T-SNE can be computationally expensive on large datasets.\n",
    "# Consider using a subset or PCA first if it's too slow.\n",
    "n_samples_tsne = min(5000, scaled_features.shape[0]) # Limit samples for performance\n",
    "indices = np.random.choice(scaled_features.shape[0], n_samples_tsne, replace=False)\n",
    "scaled_features_subset = scaled_features[indices, :]\n",
    "# pca_result_subset = pca_result[indices, :] # Can apply t-SNE on PCA results too\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=300, random_state=42, verbose=1)\n",
    "tsne_result = tsne.fit_transform(scaled_features_subset) # Use subset for T-SNE\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(x=tsne_result[:, 0], y=tsne_result[:, 1], alpha=0.6)\n",
    "plt.title(f't-SNE of Manual Features ({n_samples_tsne} samples)')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- 3. K-Means Clustering ---\n",
    "print(\"\\n--- Performing K-Means Clustering ---\")\n",
    "# Determine optimal K using the Elbow method\n",
    "inertia = []\n",
    "k_range = range(1, 11) # Check K from 1 to 10\n",
    "for k in k_range:\n",
    "    kmeans_test = KMeans(n_clusters=k, random_state=42, n_init=10) # Suppress warning\n",
    "    kmeans_test.fit(scaled_features)\n",
    "    inertia.append(kmeans_test.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_range, inertia, marker='o')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia (Within-cluster sum of squares)')\n",
    "plt.xticks(k_range)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Choose K based on the elbow plot (e.g., K=4)\n",
    "optimal_k = 4 # Adjust based on the plot\n",
    "print(f\"Selected K = {optimal_k}\")\n",
    "\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "kmeans_labels = kmeans.fit_predict(scaled_features)\n",
    "\n",
    "# Add cluster labels to the original features DataFrame (optional)\n",
    "manual_features_df['kmeans_cluster'] = kmeans_labels\n",
    "\n",
    "# Visualize K-Means clusters using PCA results\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(x=pca_result[:, 0], y=pca_result[:, 1], hue=kmeans_labels, palette='viridis', alpha=0.7, s=50)\n",
    "plt.title(f'K-Means Clustering (K={optimal_k}) Results on PCA Components')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- 4. Hierarchical Clustering ---\n",
    "print(\"\\n--- Performing Hierarchical Clustering ---\")\n",
    "# Generate the linkage matrix using Ward's method (minimizes variance within clusters)\n",
    "# Use a subset if the dataset is very large, as linkage calculation can be heavy\n",
    "n_samples_hc = min(2000, scaled_features.shape[0])\n",
    "indices_hc = np.random.choice(scaled_features.shape[0], n_samples_hc, replace=False)\n",
    "scaled_features_subset_hc = scaled_features[indices_hc, :]\n",
    "\n",
    "linked = linkage(scaled_features_subset_hc, method='ward')\n",
    "\n",
    "# Plot the dendrogram\n",
    "plt.figure(figsize=(15, 7))\n",
    "dendrogram(linked,\n",
    "           orientation='top',\n",
    "           # labels=manual_features_df.index[indices_hc].tolist(), # Optional: add labels if meaningful/small subset\n",
    "           distance_sort='descending',\n",
    "           show_leaf_counts=True,\n",
    "           truncate_mode='lastp', # Show only the last p merged clusters\n",
    "           p=30) # Adjust 'p' to control dendrogram complexity\n",
    "plt.title('Hierarchical Clustering Dendrogram (Ward, Truncated)')\n",
    "plt.xlabel('Sample Index (or Cluster Size)')\n",
    "plt.ylabel('Distance (Ward)') \n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Choose the number of clusters based on the dendrogram (e.g., by cutting at a certain height)\n",
    "num_hierarchical_clusters = 4 # Adjust based on dendrogram inspection\n",
    "print(f\"Selected number of hierarchical clusters = {num_hierarchical_clusters}\")\n",
    "\n",
    "# Apply Agglomerative Clustering\n",
    "agg_cluster = AgglomerativeClustering(n_clusters=num_hierarchical_clusters, affinity='euclidean', linkage='ward')\n",
    "hierarchical_labels = agg_cluster.fit_predict(scaled_features) # Fit on all data\n",
    "\n",
    "# Add cluster labels to the original features DataFrame (optional)\n",
    "manual_features_df['hierarchical_cluster'] = hierarchical_labels\n",
    "\n",
    "# Visualize Hierarchical clusters using PCA results\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(x=pca_result[:, 0], y=pca_result[:, 1], hue=hierarchical_labels, palette='viridis', alpha=0.7, s=50)\n",
    "plt.title(f'Hierarchical Clustering (n={num_hierarchical_clusters}) Results on PCA Components')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualizing clusters <a name=\"visualize-clusters1\"></a>\n",
    "\n",
    "We will visualize the different clusters created from the algorithms and evaluate whether these clusters correspond to specific cognitive patterns, or any other patterns observed between the different clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2\n",
    "\n",
    "### Deep feature extraction and Clustering <a name=\"deep-feature-extraction\"></a>\n",
    "\n",
    "In this section we will use unsupervised deep learning approaches like Autoencoders, Variational Autoencoders (VAE), and LSTM Autoencoders to extract latent features from the raw data or the manually selected features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring deep feature clusters\n",
    "\n",
    "We will again use algorithms such as PCA, t-SNE, k-means and hierarchical clustering to cluster the deep features and visualize the latent space. As done before we will evaluate whether these clusters correspond to specific patterns in the inspections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing generality of clusters\n",
    "\n",
    "To test the generality of these cluster we will load the warehouse data. For this dataset the user was asked to find a specific graffiti inside a warehouse full of graffiti. Although the task is very different in nature, the cognitive patterns should be similar, for example the clusters should be capable of identifying when the person is looking at a graffiti and deciding if it is the correct one or not. On the other hand, we might find that the clusters generated don't generalize well to this problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
